%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LaTeX Example: Project Report
%
% Source: http://www.howtotex.com
%
% Feel free to distribute this example, but please keep the referral
% to howtotex.com
% Date: March 2011 
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% How to use writeLaTeX: 
%
% You edit the source code here on the left, and the preview on the
% right shows you the result within a few seconds.
%
% Bookmark this page and share the URL with your co-authors. They can
% edit at the same time!
%
% You can upload figures, bibliographies, custom classes and
% styles using the files menu.
%
% If you're new to LaTeX, the wikibook is a great place to start:
% http://en.wikibooks.org/wiki/LaTeX
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Edit the title below to update the display in My Documents
%\title{Project Report}
%
%%% Preamble
\documentclass[paper=a4, fontsize=11pt]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage{fourier}

\usepackage[english]{babel}                                                         % English language/hyphenation
\usepackage[protrusion=true,expansion=true]{microtype}  
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage[pdftex]{graphicx}   
\usepackage{url}


%%% Custom sectioning
\usepackage{sectsty}
\allsectionsfont{\centering \normalfont\scshape}


%%% Custom headers/footers (fancyhdr package)
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhead{}                                            % No page header
\fancyfoot[L]{}                                         % Empty 
\fancyfoot[C]{}                                         % Empty
\fancyfoot[R]{\thepage}                                 % Pagenumbering
\renewcommand{\headrulewidth}{0pt}          % Remove header underlines
\renewcommand{\footrulewidth}{0pt}              % Remove footer underlines
\setlength{\headheight}{13.6pt}


%%% Equation and float numbering
\numberwithin{equation}{section}        % Equationnumbering: section.eq#
\numberwithin{figure}{section}          % Figurenumbering: section.fig#
\numberwithin{table}{section}               % Tablenumbering: section.tab#


%%% Maketitle metadata
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}     % Horizontal rule

\title{
        %\vspace{-1in}  
        \usefont{OT1}{bch}{b}{n}
        \normalfont \normalsize \textsc{School of random department names} \\ [25pt]
        \horrule{0.5pt} \\[0.4cm]
        \huge CSE 221 Final Project \\
        \huge       Draft 1         \\
        \horrule{2pt} \\[0.5cm]
}
\author{
        \normalfont                                 \normalsize
        Patrick Bird\\[-3pt]        \normalsize
        patbird@gmail.com\\           \normalsize
        \today
}
\date{}


%%% Begin document
\begin{document}
\maketitle
\section{Introduction}
Over the last decade, an increasing number of services are transitioning to the cloud to leverage some of its power.  Pre-configured virtual machines and unlimited object storage attract many a company.  Many of these services attract companies who do not want to invest time and money into supporting infrastructure that is not in their area of specialty.

The area of big data is also an interest to many.  Many organizations and instutions are amassing large datasets that is challenging on one hand since there is much potential to learn new connections between data that wasn't known before.  But it is also crippling from not knowing where to start analyzing and drawing connections.

With both cloud technology and big data, the infrastructure is crtical for maintaining a robust platform to explore these two areas of technology.  The institution where I work in is involved in these two areas and that is what has motivated me to understand and characterize a system.

The current project that I work on, basespace.com, leverages Amazon AWS services such as EC2, S3, SQS, and more.  And since our product is mainly the analysis of genomic data, the need for high throughput of both data, compute, and parallelism is needed.  Many of our analyses can take several hours to compute.  This timespan may seem acceptable, but as genomics and the clinical lab converge, speed will be critical for diagnosing health issues.  Any savings in time could, without sounding too cliche, save a life.

Focusing on cloud computing, I wanted to characterize a local, high-performance bare-metal compute node.  Although outside the scope of this paper, I would eventually like to extend the study to actual VMs on these compute nodes and to compare their performance with the bare metal.  For instance, how does an 8 VCPU VM with 64 GB of memory compare with its bare-metal constituents.  What would be the cost of virtualization?

Since this study involves high performance time measurement, I wanted to get as close as I could to the hardware without writing the whole thing in assembly.  Not to mention, the node runs CentOS linux, and knowing that GCC and the standard POSIX C headers were readily available, no other languages were really considered.  No special compiler options were really used either.  The only options I needed to provide were to link in math libraries for calculating the square root and for using pthreads.

So far, I have invested about 25 hours into this project thus far.  I alone have done all the work in both research, code implementation and the production of this paper.

\section{Machine Description}

The system has two processors, with each having six cores that are hyperthreaded.  This information was called from /proc/cpuinfo and matched with the information from Intel's website.  The processors are Intel Xeon E5-2620 that run at 2000.053 MHz to be exact.  There are three levels of cache - 32 KB of L1 each for data and instructions, 256 KB of L2 (both), and 15360 KB of L3 (both).  

The memory size is 128 GB of DDR3 RAM.  The potential speed is 1600 MHZ, however, the configurable clock speed is set to 1333 MHz.  The processor is setup so that it can utilize four memory channels with the RAM.  The more channels it has, the greater opportunity the processor has for read and write parallelism.  This information was found by the dmidecode command.

The network card is full duplex gigabit ethernet.

The operating system is 64-bit CentOS v6.4, kernel version v2.6.32-358.11.1.

\section{Operations}
This section will describe various operations that I estimated performance, how I came to those estimates, and how I performed measurements to measure these operations.  To begin with, this system is not a single RISC processor.  Unfortunatley for my current purposes, but to my computer's delight, there is not a one to one mapping between instructions and clock cycles.  At least for the first few operations, I couldn't merely just count up the instructions and add a little for overhead.

As I mentioned in Section 2, these processsors have multi-cores three levels of cache, around a 17-20 stage pipeline, an interprocessor communication mechanism.  Needless to say, estimating any sort of operation is difficult without an exhaustive knowledge of the internals of the processor and the system.

Since there are so many variables in the system, I wanted to set out and eliminate as many as I could before I started to measure.  For one, I wanted to bind this measurement process to a particular processor.  If my process was interrupted and switched out to a different one, I wanted to ensure that the clock that I read every time was from the same processor.

Thus, one of the first things that my process does upon startup is to set processor affinity.  There is a POSIX routine for this called \textit{sched\_setaffinity}.  When this routine is run at the beginning of my process, the process binds itself to the first processor.  With this binding, at least my clock will not vary from jumping to different CPUs.

My next goal was to elevate the priority of the process to limit context switching as much as possible.  Obviously, I wouldn't have full control over how much CPU bandwidth I could use.  Again, there is a POSIX procedure for setting the priority - \textit{setpriority}.  This process is elevated to the minimum nice value, which is the highest priority.  At this point in time, it is -20.

Both of these decisions did not come easily.  The main drawback was that the typical use case would be eliminated, at least for the time being.  When performing measurements, it is good to know what the measurement would be for typical scenearios instead of highly optimized ones.  However, what caused me to decide to bind to a processor and elevate the process' priority was again the effort to eliminate as many variables as I could.  My reasoning was that these variables can always be reintroduced later if they needed to be measured.

All the measurements are in clock cycles.  However, a simple formula exists to calculate the time that operation took:

INSERT HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

\subsection{Measurement Overhead}

How time is measured for performance metrics such as this paper is one of the more fundamental mechanisms.  Every measurement will be built on how time is measured.  And since the system is incredibly complex, measuring time is a difficult process.  One of the first decisions that needed to be made was whether to count clock cycles or to measure time through some sort of native timestamp.

At least to begin with, some of the operations were quite small which warranted the granularity of the clock cycle.  Any library call that would get the calendar time would need to have some extra code to translate the real time clock to a data structure.  This translation would add yet another cost to understanding the true overhead of the system.

Thus, \textbf{RDTSC} seemed to be the operation to go.  It is one instruction on this chipset, which would read the real time clock of the CPU.  And it is not a privleged call, so there is no overhead in reading it.  However, as I read more about the instruction and the CPU, I understood that the CPU is out of order processor.  Thus, there is no guaranteee when a certain instruction will execute.  To put it in other words, one cannot just look at the assembly and trust that the processor will execute it sequentially.  This processor has almost twenty stages in its pipeline.

Thus, there needed to be a way to serialize the calls, or create an instruction barrier.  \textbf{CPUID} seemed to be a favorite instruction to call right before \textbf{RDTSC} since it is a serializing call.  Unfortunately, this instruction comes with somewhat of a performance penalty.  Thankfully, I came across \textbf{RDTSCP}, which is a serializing \textbf{RDTSC} call.

\subsubsection{Estimation}

After the small routine to read the clock is loaded into cache, there is not much hardware interaction other than the CPU itself.  Since this is the case, a hardware estimation includes examining the software routine for performance.  There are fifteen assembly instructions in the \textit{GetRdtscp()} procedure with another four instructions for calling and returning.  In all, there about twenty instructions.  Accounting for 20\% overhead, my hardware estimation is 24 clock cycles.

The operating system does not add much overhead in this operation.  After the instructions are loaded from memory, the instructions will most likely stay in cache.  Thus, another 20\% overhead will be accounted for random context switching.  Thus, the overall estimation time is around 30 clock cycles (15 ns).

\subsubsection{Measurement}

After running the experiment a 1000 times, I get the following results:

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    Hardware Estimate & Software Estimate & Total Estimate & Measurement \\ \hline
    24 cycles & 5 cycles & 30 cyles & 35 cyles (18 ns) \\ 
    \hline
    \end{tabular}
\end{center}

My estimation was actually not as bad as I expected it to be.  My estimation was faster than what the average speed of the routine was, but close enough.  In fact, my estimation matched the minimal value that I observed over 1000 iterations.  Part of the reason why I think my estimate was fairly good was that there was not much happening here as far as the system goes.  There is no outside interface with peripheral devices or memory for that matter.

The memory issue is interesting because for the most part, my performance only took a hit during the first iteration.  The CPU had to fetch the procedure from memory and load it into its cache.  After the routine was in cache, the performance increased significantly.

As one can observe by the next grid, there is a tight range between the min and the max.  There is only a difference of 11 clock cycles with a standard deviation of 2.68 clock cycles.  The max in the table lists the max other than the first data point.  I intentionally did this for two reasons.

\begin{center}
    \begin{tabular}{ | l | l | l | l | l | l |}
    \hline
    No. of Samples & First Iteration & Min & Max (excluding 1st) & Mean & Standard Deviation \\ \hline
    1000 iterations & 53 cycles & 30 cycles & 41 cyles & 35.0 cyles & 2.68 cycles \\ 
    \hline
    \end{tabular}
\end{center}

For one, in all my measurements, I want to observe the cost of the CPU fetching the routine from memory if it has not already done so.  I also wanted to know after that, what is the next maximum value.  I followed this process for each of the operations.

\subsection{Loop Overhead}

\subsubsection{Estimation}

Adding a loop construct to the measurement routine does not introduce a heavy burden.  In reality, it is just a few more instructions to add to the measurement routine.  ANd since it is a loop, there is pointer arithemetic that needs to happen to store the clock value.  Again there is no significant operating system cost to account for, so the entire extra cost for a loop routine will fall in the hardware domain.  Using the average cost from the RDTSCP routine, I estimate that the cost for a loop will be an extra ten cycles based upon the additional hardware instructions or 38 clock cycles (19 ns).

\subsubsection{Measurement}

After running the experiment a 1000 times, I observe the following results:

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    Hardware Estimate & Software Estimate & Total Estimate & Measurement \\ \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\ 
    \hline
    \end{tabular}
\end{center}

The estimate was actually very close to the actual answer which is very pleasing.  Though, trying to estimate this routine from scratch would have been much more difficult.  Since I had the convienence of the previous metric, my estimate was able to be close to the measure value value.

\begin{center}
    \begin{tabular}{ | l | l | l | l | l | l |}
    \hline
    No. of Samples & First Iteration & Min & Max (excluding 1st) & Mean & Standard Deviation \\ \hline
    1000 iterations & 45 cycles & 45 cycles & 371 cyles & 35.0 cyles & 2.68 cycles \\ 
    \hline
    \end{tabular}
\end{center}

\subsection{Procedure}

\subsubsection{Estimation}

The cost of calling a procedure will most likely be on par with the loop construct.  In the loop construct, there is a branch, an update to a register value, and pointer arithmetic for both the lower and upper 32 bits of the clock value.  For a procedure, it will be pushing and popping registers off the stack.  Obviously, the greater number of arguments, the greater number of registers that need to be pushed and popped.

For zero arguments, there is almost no cost to calling a function other than pushing the return address and the call instruction itself.  For one argument, a register needs to be pushed, and the stack pointer needs to be adjusted.   F  Also, there is the call instruction. Then, for every variable, an additional register is pushed onto the stack.  Thus, we can use the equation

extra cycles = RDTSCP + 2 (zero arguments) + 2n (arithmetic and register) 

extra cycle = 37 + 2n

Again, the cost of the operating system is neglible since the CPU is mainly just executing instructions from its local cache.  Thus, plugging in the values from the RDTSCP function, we get the following table:

37
39
41
43
45
47
49

In the C routines themselves, I ensured that the arguments were being referenced so the compiler would not try to optimize them away.

\subsubsection{Measurement}

Again, stepping on the shoulders of the RDTSCP measurement has been beneficial.  The measurements are within the bounds of my estimation.

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    Hardware Estimate & Software Estimate & Total Estimate & Measurement \\ \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\ \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\  \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\  \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\  \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\  \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\  \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\ 
    \hline
    \end{tabular}
\end{center}

It is interesting to note that functions with two, three, four, and six arguments had the same average cost of 40 clock cycles.  Not to mention that all eight enumerations of functions are within five clock cyles of each other.  So in some ways there is a linear relationship between additional arguments and the time cost.  However, the cost is neglible.

The various metrics for the different function calls are enumerated here:

\begin{center}
    \begin{tabular}{ | l | l | l | l | l | l |}
    \hline
    No. of Samples & First Iteration & Min & Max (excluding 1st) & Mean & Standard Deviation \\ \hline
    1000 iterations & 45 cycles & 45 cycles & 371 cyles & 35.0 cyles & 2.68 cycles \\ 
    \hline
    \end{tabular}
\end{center}

\subsection{System Call}

\subsubsection{Estimation}

For a system call, linux needs to trap into the OS. Thus, there is a heavier cost for a system call as opposed to a user call.  The same registers are pushed onto the stack as a user call.  But there also needs to be some sort of interrupt that happens and an elevation of privleges.  After the user function makes a system call,  the kernel traps into its own routine and takes over.  The kernel then figures out which system call to route to and saves all relevant user state so when it is done, it can transfer control flow back to the user process.  Within the system call itself will copy any releveant user data to its own address space and perform its operation.  After the work is finished, the kernel transfers control flow back to the user process.

The system call is much more expensive than a normal function call because of the elevation of privleges.  Not to mention, there is more copying of data from user space to kernel space and back again.  And there is more state to save.

In the case of a system call, there is more overhead in the operating system than hardware.  As far as hardware is concerned, the CPU will most likely have to fetch the procedure from kernel's address space when it needs to be loaded.  Since system calls happen fairly often, a lot of the instruction data will most likely already be in cache.  But this cost is very similar to a procedure in user space.  It is just in a different place in memory.  Thus, the hardware cost is the base from a user function call - 37 clock cycles.

However, there is a greater cost to the OS here.  In my case, I will measure \textit{getpid()}.  There are at least seven different stages enumerated for this system call.  For each stage, I added an estimate.



\begin{tabular}{ |l|l| }
  \hline
  \multicolumn{2}{|c|}{OS Cost} \\
  \hline
  10 & User state is saved \\
  20 & Elevation of privleges \\
  10 & System function called \\
  10 & Any user data that is needed is copied into kernel space with correct privleges \\
  20 & System call executes \\
  10 & Execution is restored to user \\
  \hline
  80 & total \\
  \hline
\end{tabular}


In all, I estimate about 100 clock cycles will happen just for the operating system part of the system call.  Adding to the hardware cost, I estimate that a system call will take about 117 clock cycles.

\subsubsection{Measurement}

This measurement is the first measurement where I was somewhat dramatically different than the estimation.  In fact, other than the very first call, which took 2427 clock cycles, the average call was a measly 42 clock cycles.  The minimum was 36!  This cost is barely above the user call.  One reason for this large disparity is most likely the efficiency of \textit{getpid()} itself.  The function does not probably take as long to execute at all.  It probably just looks up the address of the calling process in some memory mapped table.  Also, the transfer from user to kernel and back again is much faster than I had assumed.  Again, the address of the procedure must be executed right after the elevation of privleges.  And since no substantial user data needs to be copied, \textit{getpid()} is fairly efficient.

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    Hardware Estimate & Software Estimate & Total Estimate & Measurement \\ \hline
    33 cycles & 5 cycles & 38 cyles & 47 cyles (24 ns) \\ 
    \hline
    \end{tabular}
\end{center}

The following statistical metrics are here.  Notice the cost of the initial call.

\begin{center}
    \begin{tabular}{ | l | l | l | l | l | l |}
    \hline
    No. of Samples & First Iteration & Min & Max (excluding 1st) & Mean & Standard Deviation \\ \hline
    1000 iterations & 45 cycles & 45 cycles & 371 cyles & 35.0 cyles & 2.68 cycles \\ 
    \hline
    \end{tabular}
\end{center}







%%% End document
\end{document}